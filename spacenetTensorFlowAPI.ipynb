{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaceNet Utilities Path Already Exists\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "spaceNetUtilitiesPath = '/opt/utilities/python/'\n",
    "if not spaceNetUtilitiesPath in sys.path:\n",
    "    print('adding spaceNetUtilitiesPath')\n",
    "    sys.path.extend([spaceNetUtilitiesPath])\n",
    "else:\n",
    "    print('SpaceNet Utilities Path Already Exists')\n",
    "from spaceNetUtilities import geoTools as gT\n",
    "from spaceNetUtilities import labelTools as lT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/opt/utilities/python',\n",
       " '/software/spaceNetTensorFlowObj',\n",
       " '/opt/models',\n",
       " '/opt/models/slim',\n",
       " '/usr/lib/python2.7',\n",
       " '/usr/lib/python2.7/plat-x86_64-linux-gnu',\n",
       " '/usr/lib/python2.7/lib-tk',\n",
       " '/usr/lib/python2.7/lib-old',\n",
       " '/usr/lib/python2.7/lib-dynload',\n",
       " '/usr/local/lib/python2.7/dist-packages',\n",
       " '/usr/lib/python2.7/dist-packages',\n",
       " '/usr/local/lib/python2.7/dist-packages/IPython/extensions',\n",
       " '/root/.ipython',\n",
       " '/opt/utilities/python/']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "r\"\"\"Convert raw PASCAL dataset to TFRecord for object_detection.\n",
    "\n",
    "Example usage:\n",
    "    ./create_pascal_tf_record --data_dir=/home/user/VOCdevkit \\\n",
    "        --year=VOC2012 \\\n",
    "        --output_path=/home/user/pascal.record\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import hashlib\n",
    "import io\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "from lxml import etree\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def dict_to_tf_example(data, label_map_dict, img_path=[], dataDir=''):\n",
    "    \"\"\"Convert XML derived dict to tf.Example proto.\n",
    "  \n",
    "    Notice that this function normalizes the bounding box coordinates provided\n",
    "    by the raw data.\n",
    "  \n",
    "    Args:\n",
    "      data: dict holding PASCAL XML fields for a single image (obtained by\n",
    "        running dataset_util.recursive_parse_xml_to_dict)\n",
    "      dataset_directory: Path to root directory holding PASCAL dataset\n",
    "      label_map_dict: A map from string label names to integers ids.\n",
    "      ignore_difficult_instances: Whether to skip difficult instances in the\n",
    "        dataset  (default: False).\n",
    "      image_subdirectory: String specifying subdirectory within the\n",
    "        PASCAL dataset directory holding the actual image data.\n",
    "  \n",
    "    Returns:\n",
    "      example: The converted tf.Example.\n",
    "  \n",
    "    Raises:\n",
    "      ValueError: if the image pointed to by data['filename'] is not a valid JPEG\n",
    "    \"\"\"\n",
    "    if not img_path:\n",
    "        img_path = data['filename']\n",
    "    \n",
    "    with tf.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = PIL.Image.open(encoded_jpg_io)\n",
    "    if image.format != 'JPEG':\n",
    "        raise ValueError('Image format not JPEG')\n",
    "    key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "    width = int(data['size']['width'])\n",
    "    height = int(data['size']['height'])\n",
    "\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "    truncated = []\n",
    "    poses = []\n",
    "    difficult_obj = []\n",
    "    \n",
    "    if 'object' in data:\n",
    "        for obj in data['object']:\n",
    "            difficult = bool(int(obj['difficult']))\n",
    "        \n",
    "\n",
    "            difficult_obj.append(int(difficult))\n",
    "\n",
    "            xmin.append(float(obj['bndbox']['xmin']) / width)\n",
    "            ymin.append(float(obj['bndbox']['ymin']) / height)\n",
    "            xmax.append(float(obj['bndbox']['xmax']) / width)\n",
    "            ymax.append(float(obj['bndbox']['ymax']) / height)\n",
    "            classes_text.append(obj['name'].encode('utf8'))\n",
    "            classes.append(label_map_dict[obj['name']])\n",
    "            truncated.append(int(obj['truncated']))\n",
    "            poses.append(obj['pose'].encode('utf8'))\n",
    "            #print(xmin)\n",
    "            #print(ymin)\n",
    "            #print(xmax)\n",
    "            #print(ymax)\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'image/height': dataset_util.int64_feature(height),\n",
    "                'image/width': dataset_util.int64_feature(width),\n",
    "                'image/filename': dataset_util.bytes_feature(\n",
    "                    data['filename'].encode('utf8')),\n",
    "                'image/source_id': dataset_util.bytes_feature(\n",
    "                    data['filename'].encode('utf8')),\n",
    "                'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "                'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "                'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "                'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
    "                'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
    "                'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
    "                'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
    "                'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "                'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "                'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),\n",
    "                'image/object/truncated': dataset_util.int64_list_feature(truncated),\n",
    "                'image/object/view': dataset_util.bytes_list_feature(poses),\n",
    "            }))\n",
    "        return example\n",
    "\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def createTFRecord(txtList, label_map_path, output_dir, dataDir='', maxSamples=-1):\n",
    "    writer = tf.python_io.TFRecordWriter(output_dir)\n",
    "    label_map_dict = label_map_util.get_label_map_dict(label_map_path)\n",
    "\n",
    "\n",
    "    rowList = []\n",
    "    with open(txtList, 'r') as f:\n",
    "        for row in f:\n",
    "            row = row.rstrip()\n",
    "            rowList.append(row.split(' '))\n",
    "            \n",
    "    if maxSamples ==-1:\n",
    "        maxSamples == len(rowList)\n",
    "    maxLength = min(len(rowList), maxSamples)\n",
    "    for row in tqdm(rowList[0:maxLength]):\n",
    "        imgPath = row[0]\n",
    "        labelPath = row[1]\n",
    "\n",
    "        if dataDir != \"\":\n",
    "            labelPath = os.path.join(dataDir, os.path.basename(labelPath))\n",
    "            imgPath = os.path.join(dataDir, os.path.basename(imgPath))\n",
    "        with tf.gfile.GFile(labelPath, 'r') as fid:\n",
    "            xml_str = fid.read()\n",
    "        xml = etree.fromstring(xml_str)\n",
    "        data = dataset_util.recursive_parse_xml_to_dict(xml)['annotation']\n",
    "\n",
    "        tf_example = dict_to_tf_example(data, label_map_dict, img_path=imgPath)\n",
    "        if tf_example:\n",
    "            #print (row) \n",
    "            writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    return 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import hashlib\n",
    "import io\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from lxml import etree\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12322/12322 [03:25<00:00, 60.10it/s]\n",
      "100%|██████████| 3079/3079 [00:28<00:00, 107.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePath = '/data/spacenetV2_TrainData/AOI_2_Vegas_Train_PASCALVOC/trainval.txt'\n",
    "pathpbTxt = '/data/spacenetV2_TrainData/AOI_2_Vegas_Train_PASCALVOC/data/spacenet_label_map.pbtxt'\n",
    "output_dir = '/data/spacenetV2_TrainData/AOI_2_Vegas_Train_PASCALVOC/tf_train1.record'\n",
    "dataDir = '/data/spacenetV2_TrainData/AOI_2_Vegas_Train_PASCALVOC/annotations'\n",
    "createTFRecord(filePath, pathpbTxt, output_dir, dataDir=dataDir)\n",
    "\n",
    "filePath = '/data/spacenetV2_TrainData/AOI_2_Vegas_Train_PASCALVOC/test.txt'\n",
    "output_dir = '/data/spacenetV2_TrainData/AOI_2_Vegas_Train_PASCALVOC/tf_test1.record'\n",
    "createTFRecord(filePath, pathpbTxt, output_dir, dataDir=dataDir)\n",
    "\n",
    "\n",
    "#with tf.gfile.GFile(path, 'r') as fid:\n",
    "#    xml_str = fid.read()\n",
    "#xml = etree.fromstring(xml_str)\n",
    "#data = dataset_util.recursive_parse_xml_to_dict(xml)['annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3080/3080 [00:43<00:00, 71.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': '/usr/local/share/data/spacenetV2_TrainData/AOI_2_Vegas_Train_PASCALVOC/RGB-PanSharpen/RGB-PanSharpen__-115.2513576_36.2230676999.tif',\n",
       " 'folder': 'spacenetV2',\n",
       " 'object': [{'bndbox': {'xmax': '156',\n",
       "    'xmin': '51',\n",
       "    'ymax': '76',\n",
       "    'ymin': '4'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '373', 'xmin': '287', 'ymax': '101', 'ymin': '49'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '298', 'xmin': '222', 'ymax': '92', 'ymin': '0'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '400', 'xmin': '387', 'ymax': '89', 'ymin': '55'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '400', 'xmin': '387', 'ymax': '182', 'ymin': '139'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '375', 'xmin': '290', 'ymax': '186', 'ymin': '131'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '299', 'xmin': '221', 'ymax': '239', 'ymin': '178'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '139', 'xmin': '51', 'ymax': '149', 'ymin': '86'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '142', 'xmin': '52', 'ymax': '241', 'ymin': '171'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '149', 'xmin': '53', 'ymax': '323', 'ymin': '244'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '297', 'xmin': '203', 'ymax': '324', 'ymin': '252'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '128', 'xmin': '53', 'ymax': '400', 'ymin': '338'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '371', 'xmin': '301', 'ymax': '361', 'ymin': '309'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '400', 'xmin': '393', 'ymax': '363', 'ymin': '317'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '383', 'xmin': '370', 'ymax': '396', 'ymin': '381'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'},\n",
       "  {'bndbox': {'xmax': '360', 'xmin': '317', 'ymax': '400', 'ymin': '384'},\n",
       "   'difficult': '0',\n",
       "   'name': 'building',\n",
       "   'pose': 'Left',\n",
       "   'truncated': '0'}],\n",
       " 'segmented': '1',\n",
       " 'size': {'depth': '3', 'height': '400', 'width': '400'},\n",
       " 'source': {'annotation': 'PASCALVOC2012', 'database': 'spacenetV2'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'building': 1,\n",
       " u'cable_distribution_cabinet': 2,\n",
       " u'catenary_mast': 3,\n",
       " u'compensator': 4,\n",
       " u'connection': 5,\n",
       " u'generator': 6,\n",
       " u'insulator': 7,\n",
       " u'none_of_the_above': 0,\n",
       " u'plant': 8,\n",
       " u'pole': 9,\n",
       " u'portal': 10,\n",
       " u'station': 11,\n",
       " u'sub_station': 12,\n",
       " u'substation': 12,\n",
       " u'switch': 13,\n",
       " u'terminal': 14,\n",
       " u'tower': 15,\n",
       " u'transformer': 16}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
